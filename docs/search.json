[
  {
    "objectID": "index.html#introduction",
    "href": "index.html#introduction",
    "title": "CER-BEANS: Community Engaged Research Balanced Assessments and Expressions with Nuanced Scores",
    "section": "Introduction",
    "text": "Introduction\n\n‚ÄúEvery little bean must be heard as well as seen!‚Äù\n‚Äî Erich Maria Remarque, All Quiet on the Western Front\n\n\n\n\nA hill of important beans just waiting to be counted as imagined by Adobe Firefly\n\n\nQuantitative measures capture only a small piece of the (bean) pie, but people in academia ‚ù§Ô∏è&nbsplove¬†‚ù§Ô∏è putting numbers on things and counting them (beans).\nRather than sitting back and stewing like a pot of vegetarian chili while fretting about whether or not faculty committees and administrators will count the kinds of beans I hope they would count, I decided to create my own set of beans for them to count. Therefore:\nCommunity Engaged Research Broad Evaluation and Assessments with Nuanced Scores (CER-BEANS)CER-BEANS is pronounced ‚ÄúSir¬†Beans.‚Äù\nI was inspired by the Altmetric badge, so I want to make sure to create a system of beans that is:\n\nEasy to grok and nice to look at.\nAuthentic and meaningful to the work and experiences of community engaged researchers.\nUsable as a critical framing for the kind of work community engaged researchers should be focusing on.\nTranslatable, transferable, robust, resilient, dynamic, and extensible.\n\nTo grok something is to understand it intuitively and deeply.How ‚Äôbout these beans?\n\nPretty radicle, eh?\n\n\n\n\n\n\nIf You Choose to Die on This Hill (of Beans)‚Ä¶\n\n\n\nI am open to collaboration, dialogue, and disagreement. You can even open an issue if you‚Äôd like to make it official. Contributions are welcomed, please read the Code of Conduct."
  },
  {
    "objectID": "index.html#identifying-the-metrics",
    "href": "index.html#identifying-the-metrics",
    "title": "CER-BEANS: Community Engaged Research Balanced Assessments and Expressions with Nuanced Scores",
    "section": "Identifying the Metrics",
    "text": "Identifying the Metrics\n\n‚ÄúYou never cook onions with your beans. That‚Äôs a recipe for tear gas.‚Äù\n‚Äî Justin Swapp, The Shadow‚Äôs Servant\n\n\n\n\nAn image of medieval academics counting beans as imagined by Adobe Firefly\n\n\nWhen evaluating community-engaged programs, it‚Äôs important to consider various metrics that assess different aspects of the program‚Äôs effectiveness and impact.\n\n\n\n\n\n\nIf You Had a Roomful of Awards that Didn‚Äôt Mean Beans‚Ä¶\n\n\n\nIt is important to remember a number, a score, or even a collection or bean hill of scores or numbers, do not tell the whole story of your community engaged research. This framework is provided to help you tell that story using a system that is easily recognizable and considered a valid form of evidence.\nThese numbers are a guidepost for your readers‚Äìor more likely‚Äìyour evaluators.\n\n\nNow that I‚Äôve provided the warning, remember that academics are first and foremost makers of bean stalks: we are trained to make cases and construct narratives. Here are some tips for you to consider about what CER-BEANS does provide for you as you construct a narrative around your work:I make bean stalks, I‚ÄômA builder, like yourself.‚Äì Edna St.¬†Vincent Millay, The Bean-Stalk\n\nü™û Reflectionüì∏ Snapshotüó∫Ô∏è Map\n\n\nIt provides an overall reflection on your work and where you have focused your energies. CER-BEANS gives you an indication of the impact your work has had, allowing you to discuss your successes.\n\n\nIt provides a snapshot of where you are in a longer process, what has worked well so far, and where you will be focusing your efforts in the near future.\n\n\nIt provides a rough map of where your and your collaborators, partners, and participants can take the work moving forward.\n\n\n\nCER-BEANS focuses on five areas, or shall we say, hills, and they each result in an area score. Each of the area scores contribute to the overall CER-BEANS score. These are the five areas:\n\nParticipants\nEngagement\nInfrastructures\nOutputs\nSustainability\n\nEach of the area scores (\\(S_a\\)) follow a predictable pattern, that includes some impact number (\\(I_a\\)) that is amplified by a set of area component ratings (\\(R_a\\), individual ratings represented by \\(r_1 \\ldots r_a\\)). Here is the general formula for an area score:\n\\[\nS_a = I_a \\times (1 + \\frac{\\sum r_{a1} \\ldots r_{an}}{|R_a|})\n\\]\ncontribute to the individual area scores, each of which contribute to the overall CER-BEANS score.\nEach of these areas and their components are described in some detail below. The idea, the math, the concepts, are all licensed under a CC BY-SA 4.0 license, so you are welcomeThe code itself is licensed similarly under an MIT License.\nto take these ideas and adapt them to your particular needs and preferences (as long as you give credit where credit is due and share your adapted work alike)."
  },
  {
    "objectID": "index.html#participants",
    "href": "index.html#participants",
    "title": "CER-BEANS: Community Engaged Research Balanced Assessments and Expressions with Nuanced Scores",
    "section": "Participants",
    "text": "Participants\n\n\n\n\n\n\n  \n    \n    \n      marginalized_proportions\n      intersectionally_marginalized\n      participants_value\n    \n  \n  \n    No Marginalized Participants\nNo Intersectionally Marginalized Participants\n0.10\n    A Few Marginalized Participants\nA Few Intersectionally Marginalized Participants\n0.25\n    Some Marginalized Participants\nSome Intersectionally Marginalized Participants\n0.33\n    Just Under Half Marginalized Participants\nJust Under Half Intersectionally Marginalized Participants\n0.40\n    About Half Marginalized Participants\nAbout Half Intersectionally Marginalized Participants\n0.50\n    Just Over Half Marginalized Participants\nJust Over Half Intersectionally Marginalized Participants\n0.75\n    Mostly Marginalized Participants\nMostly Marginalized Intersectionally Participants\n0.85\n    Predominantly Marginalized Participants\nPredominantly Intersectionally Marginalized Participants\n0.90\n    Nearly All Marginalized Participants\nNearly All Intersectionally Marginalized Participants\n0.95\n    All Marginalized Participants\nAll Marginalized Intersectionally Participants\n1.00\n  \n  \n  \n\n\n\n\n\nNumber of Participants\nHow many participants involved? This is \\(p_n\\). For this example, there are 6 participants.\n\n\n\n\n\nMarginalized Proportions Score\nHow many of the participants represent and come from marginalized identities and communities? This is \\(p_m\\).\nAlso, are you working directly with these marginalized participants, or are you working with others (such as teachers or health care workers) who are working with these identities and communities?\nIt is up to your\n\n\n\n\n\nIntersectionally Marginalized Score\n\nintersectionally_marginalized_value <- .95\nintersectionally_marginalized_coefficient <- 1\n# 0.85 indicates one degree away, e.g., students of teachers, while 1 indicates\n# direct engagement\n\n\n\nCalculate Participation Score\n\n\\(p_s = p_n \\times \\frac{(\\beta_m \\times p_m) + (\\beta_i \\times p_i)}{2}\\)\n\n\n\n\n\n\n\n  \n    \n    \n      number_of_participants\n      marginalized_proportions\n      intersectionally_marginalized\n      participant_average\n      participant_amplifier\n      participant_score\n    \n  \n  \n    6\n1\n0.95\n0.98\n1.98\n11.88"
  },
  {
    "objectID": "index.html#engagement",
    "href": "index.html#engagement",
    "title": "CER-BEANS: Community Engaged Research Balanced Assessments and Expressions with Nuanced Scores",
    "section": "Engagement",
    "text": "Engagement\n\n\n\n\n\n\n  \n    \n    \n      frequency\n      duration\n      value\n    \n  \n  \n    Once\nOne Day\n0.10\n    Once Per Year\nLess Than A Week\n0.25\n    Several Times Per Year\nOne Week\n0.33\n    Every Other Month\n2-3 Weeks\n0.40\n    Once Per Month\nOne Month\n0.50\n    Every Other Week\nOne Semester\n0.75\n    Once Per Week\nOne Year\n0.85\n    2-4 Times Per Week\n2-3 Years\n0.90\n    5 Times Per Week\n3-10 Years\n0.95\n    Daily\n10+ Years\n1.00\n  \n  \n  \n\n\n\n\n\nEngagement Hours\n\nengagement_hours <- 16\n\n\n\nFrequency\n\nfrequency_score <- 0.85\n\n\n\nDuration\n\nduration_score <- 0.75\n\n\n\nCalculate Engagement Score\n\n\\(e_s = e_h \\times \\frac{\\sum{e_d, e_f}}{2}\\)\n\n\nengagement_average <- round(((duration_score + frequency_score) / 2), 2)\nengagement_amplifier <- (1 + engagement_average)\nengagement_score <- (engagement_hours * engagement_amplifier)\n\nengagement_score_frame <- data.frame(\n  engagement_hours = engagement_hours,\n  duration_score = duration_score,\n  frequency_score = frequency_score,\n  engagement_average = engagement_average,\n  engagement_amplifier = engagement_amplifier,\n  engagement_score = engagement_score\n)\nengagement_score_frame |>\n  gt()\n\n\n\n\n\n  \n    \n    \n      engagement_hours\n      duration_score\n      frequency_score\n      engagement_average\n      engagement_amplifier\n      engagement_score\n    \n  \n  \n    16\n0.75\n0.85\n0.8\n1.8\n28.8"
  },
  {
    "objectID": "index.html#infrastructure-score",
    "href": "index.html#infrastructure-score",
    "title": "CER-BEANS: Community Engaged Research Balanced Assessments and Expressions with Nuanced Scores",
    "section": "Infrastructure Score",
    "text": "Infrastructure Score\n\n\n\n\n\n\n  \n    \n    \n      purpose\n      co_construction\n      value\n    \n  \n  \n    Promoting Efficiency Only\nInitiation and Construction From One Party\n0.10\n    Promoting Predominantly Efficiency And Recognizing Plurality and Multivocality\nInitiation and Construction From One Party With Feedback By Another\n0.50\n    Promoting Mostly Efficiency And Recognizing Plurality and Multivocality\nInitiation From One Party and Construction By Another\n0.90\n    Promoting Mostly Efficiency And Recognizing Plurality, Multivocality, and Honor\nInitiated and Constructed Mostly Equitably\n0.95\n    Promoting Efficiency, Plurality, Multivocality, and Honor Equitably\nInitiated and Constructed Equitably\n1.00\n  \n  \n  \n\n\n\n\n\nNumber of Intrastructure/Intermediate Products\n\nnumber_of_infrastructure_products <- 8\n\n\n\nInfrastructure Purpose\n\ninfrastructure_purpose <- 0.9\n\n\n\nInfrastructure Co-Construction\n\ninfrastructure_co_construction <- 0.1\n\n\n\nCalculate Infrastructure Score\n\n\\(i_s = i_p \\times \\frac{i_u + i_c}{2}\\)\n\n\ninfrastructure_average <- round(((infrastructure_purpose + infrastructure_co_construction) / 2), 2)\ninfrastructure_amplifier <- (1 + infrastructure_average)\ninfrastructure_score <- (number_of_infrastructure_products * infrastructure_amplifier)\n\ninfrastructures_score_frame <- data.frame(\n  number_of_infrastructure_products = number_of_infrastructure_products,\n  infrastructure_purpose = infrastructure_purpose,\n  infrastructure_co_construction = infrastructure_co_construction,\n  infrastructure_average = infrastructure_average,\n  infrastructure_amplifier = infrastructure_amplifier,\n  infrastructure_score = infrastructure_score\n)\ninfrastructures_score_frame |>\n  gt()\n\n\n\n\n\n  \n    \n    \n      number_of_infrastructure_products\n      infrastructure_purpose\n      infrastructure_co_construction\n      infrastructure_average\n      infrastructure_amplifier\n      infrastructure_score\n    \n  \n  \n    8\n0.9\n0.1\n0.5\n1.5\n12"
  },
  {
    "objectID": "index.html#outputs-score",
    "href": "index.html#outputs-score",
    "title": "CER-BEANS: Community Engaged Research Balanced Assessments and Expressions with Nuanced Scores",
    "section": "Outputs Score",
    "text": "Outputs Score\n\n\n\n\n\n\n  \n    \n    \n      venues\n      inclusion\n      value\n    \n  \n  \n    Only One Type of Venue\nNo Inclusion\n0.10\n    Predominantly One Type of Venue\nMember Check Opportunities\n0.50\n    Mostly One Type of Venue\nInclusion in Writing\n0.90\n    Almost Even Mix of Venues\nInclusion in Data Curation, Analysis, and Writing\n0.95\n    Even Mix of Venues\nFull Partnership\n1.00\n  \n  \n  \n\n\n\n\n\nNumber of Outputs Products\n\nnumber_of_outputs <- 1\n\n\n\nDistribution of Venues\n\ndistribution_of_venues <- 0.1\n\n\n\nInclusion of Participants and Partners\n\ninclusion_of_participants <- 0.9\n\n\n\nCalculate Outputs Score\n\noutputs_average <- round(((distribution_of_venues + inclusion_of_participants) / 2), 2)\noutputs_amplifier <- (1 + outputs_average)\noutputs_score <- (number_of_outputs * outputs_amplifier)\n\noutputs_score_frame <- data.frame(\n  number_of_outputs = number_of_outputs,\n  distribution_of_venues = distribution_of_venues,\n  inclusion_of_participants = inclusion_of_participants,\n  outputs_average = outputs_average,\n  outputs_amplifier = outputs_amplifier,\n  outputs_score = outputs_score\n)\noutputs_score_frame |>\n  gt()\n\n\n\n\n\n  \n    \n    \n      number_of_outputs\n      distribution_of_venues\n      inclusion_of_participants\n      outputs_average\n      outputs_amplifier\n      outputs_score\n    \n  \n  \n    1\n0.1\n0.9\n0.5\n1.5\n1.5"
  },
  {
    "objectID": "index.html#sustainability",
    "href": "index.html#sustainability",
    "title": "CER-BEANS: Community Engaged Research Balanced Assessments and Expressions with Nuanced Scores",
    "section": "Sustainability",
    "text": "Sustainability\n\n\n\n\n\n\n  \n    \n    \n      responsibility\n      material\n      value\n    \n  \n  \n    Responsibility Distributed to One Partner\nNo Material Support\n0.10\n    Responsibility Predominantly Distributed to One Partner\nMaterial Support Predominantly Through One Partner\n0.50\n    Responsibility Mostly Distributed to One or More Partners\nMaterial Support Mostly Through One or More Partners\n0.90\n    Almost Equitable Distribution of Responsibility Across Partners\nMaterial Support Almost Equitably Distributed Across Partners\n0.95\n    Equitable Distribution of Responsibility Across Partners\nEquitable Material Support Across Partners\n1.00\n  \n  \n  \n\n\n\n\n\nNumber of Institutional Partners\n\nnumber_of_partners <- 2\n\n\n\nDistribution of Responsibility\n\ndistribution_of_responsibility <- 0.5\n\n\n\nDistribution of Material Support\n\ndistribution_of_material_support <- 0.1\n\n\n\nCalculate Sustainability Score\n\nsustainability_average <- round(((distribution_of_responsibility + distribution_of_material_support) / 2), 2)\nsustainability_amplifier <- (1 + sustainability_average)\nsustainability_score <- (number_of_partners * sustainability_amplifier)\n\nsustainability_score_frame <- data.frame(\n  number_of_partners = number_of_partners,\n  distribution_of_responsibility = distribution_of_responsibility,\n  distribution_of_material_support = distribution_of_material_support,\n  sustainability_average = sustainability_average,\n  sustainability_amplifier = sustainability_amplifier,\n  sustainability_score = sustainability_score\n)\nsustainability_score_frame |>\n  gt()\n\n\n\n\n\n  \n    \n    \n      number_of_partners\n      distribution_of_responsibility\n      distribution_of_material_support\n      sustainability_average\n      sustainability_amplifier\n      sustainability_score\n    \n  \n  \n    2\n0.5\n0.1\n0.3\n1.3\n2.6"
  },
  {
    "objectID": "index.html#overall-representation",
    "href": "index.html#overall-representation",
    "title": "CER-BEANS: Community Engaged Research Balanced Assessments and Expressions with Nuanced Scores",
    "section": "Overall Representation",
    "text": "Overall Representation\n\n‚ÄúRed Beans and Ricely Yours‚Äù\n‚Äì Louis Armstrong\n\n\n\n\n‚ÄúHere are my beans, come count them!‚Äù As imagined by Adobe Firefly.\n\n\n\n\n\n\nSimple Badge\n\n\n\nAn example of a simple badge that simply presents the proportionality of the project with the total score.\n\n\n\n\nDetailed Badge\n\n\n\nAn example of a detailed badge. This badge contains multiple levels of information including the total score, individual scores, and raw scores."
  }
]